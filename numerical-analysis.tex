\subsection{Analysis}
\label{sec.num.analysis}

\subsubsection{Inline analysis with yt}

Analyzing the results of simulations in detail requires both tools to ask
sophisticated questions of data, and the ability to process vast quantities of
data at high-cadence.  As simulations grow in size and complexity, storing data
for post-processing becomes simply intractable.  To cope with this, we have
instrumented Enzo with the ability to conduct analysis during the course of a
simulation.  This enables analyzing with extremely high cadence (even as often
as every subcycle of the finest refinement level), as well as without
attempting to write an entire checkpoint output to disk.  The current mechanism
for conducting analysis in Enzo during the course of the simulation utilizes
the same compute resources as used by the simulation itself; this is often
referred to as \textit{in situ} visualization.  Utilizing a
dynamically-scheduled second set of computing resources, often referred to as
\textit{co-scheduled} visualization, provides greater flexibility and overall
throughput at the expense of simplicity.

We expose Enzo's mesh geometry and fluid quantities to the analysis platform
\texttt{yt} \citep{2011ApJS..192....9T, 2011arXiv1112.4482T}.  At compile time,
Enzo is (dynamically or statically) linked against the Python and NumPy
libraries necessary to create proxy objects exposing the mesh geometry,
fluid quantities and particle arrays as NumPy arrays.  This information is then
passed to a special handler inside \texttt{yt}.  \texttt{yt} interprets the
mesh and fluid information and, without saving data to disk except as
explicitly requested, constructs a native representation of the in-memory state
of the simulation that appears identical to an on-disk simulation output.
Enzo then executes a user-provided analysis script, which is able to access the
in-memory simulation object.  Once the analysis script has returned control to
Enzo, the simulation proceeds.  This process can occur at either the top of the
main ``EvolveHierarchy'' loop or at the end of a timestep at the finest level,
and the frequency with which it is called is adjustable by a run-time
parameter.  During the course of conducting analysis, this simulation is halted
until the conclusion of the analysis.

Most analysis operations that can be performed on simulations that reside on
disk can be performed on in-memory simulations in \texttt{yt}.  This includes
projections (i.e., line integrals, both on- and off-axis), slices, 1-, 2-, and
3-D fluid phase distributions, calculation of derived quantities and arbitrary
data selection.  As of version 2.5 of \texttt{yt},  the Rockstar phase-space
halo finder \citep{2013ApJ...762..109B} can be executed through \texttt{yt} on
in-memory Enzo data.  Operations that currently cannot be conducted on
in-memory datasets are those that require spatial decomposition of data; for
instance, calculating marching cubes on a data object with \texttt{yt} is a
fully local operation and can be conducted \textit{in situ}.  However,
calculating topologically-connected sets requires a spatial decomposition of
data and can thus not be conducted \textit{in situ}.  This prohibition extends
to most halo finding operations, most multi-level parallelism operations,
volume rendering and connected set identification.

Where microphysical solvers or other operator-split physics calculations can be
done in Python, \texttt{yt} can serve as a driver for these calculations.  A
major feature set that is currently being developed is to pass structured
(i.e., non-fluid) information back from \texttt{yt} into Enzo.  For instance,
this could be the result of semi-analytic models of the growth and evolution of
star clusters, galaxy particle feedback parameters that have been influenced by
merger-tree analysis, or even spectral energy distributions that are calculated
within \texttt{yt} and provided to Enzo as input into radiative transfer
calculations.  Future versions will include this, as well as the ability to
dynamically allocate compute resources to \texttt{yt} such that the simulation
may proceed asynchronously with analysis (\textit{co-scheduled} analysis).
With this functionality will also come the ability to dynamically partition
data, such that spatially-decomposed operations such as volume rendering become
feasible during the course of a simulation.

\subsubsection{Tracer particles}

\subsubsection{Shock finding}

